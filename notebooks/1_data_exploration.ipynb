{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"artefact-taxonomy\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_uri = \"gs://artefact-taxonomy-classification-datasets/3P_mirakl_multilang_v1\"\n",
    "\n",
    "\n",
    "CUTOFF = 5\n",
    "\n",
    "# Define the product_id and target / label\n",
    "id_col = \"adeo_product_id\"\n",
    "title_col = \"title\"\n",
    "language_col = \"lang\"\n",
    "description_raw = \"description\"\n",
    "label_raw_col = \"mirakl_model_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM `artefact-taxonomy.pem_uc_add_datasets.temp_simplon`\n",
    "\"\"\"\n",
    "\n",
    "df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the data\n",
    "- 100 mirakl classes\n",
    "- with 4 other attributes:\n",
    "    style: 02419\n",
    "    color: 01746\n",
    "    shape: 00562\n",
    "    battery included: 15344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove classes with samples <= CUTOGFF\n",
    "df_cut = df[df[label_raw_col].map(df[label_raw_col].value_counts()) >= CUTOFF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adeo_product_id</th>\n",
       "      <th>mirakl_model_code</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4565914</td>\n",
       "      <td>4565914</td>\n",
       "      <td>4565914</td>\n",
       "      <td>4565914</td>\n",
       "      <td>4565914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3158410</td>\n",
       "      <td>3202</td>\n",
       "      <td>3885904</td>\n",
       "      <td>3</td>\n",
       "      <td>3040743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>12105401</td>\n",
       "      <td>202265|PAPIER_PEINT|PAPIER_PEINT_FRISE_ET_FIBR...</td>\n",
       "      <td>Vis à métaux Ultima à tête cylindrique hexagon...</td>\n",
       "      <td>FR</td>\n",
       "      <td>Papier peint intissé solide, résistant à l'eau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9</td>\n",
       "      <td>148827</td>\n",
       "      <td>691</td>\n",
       "      <td>2810387</td>\n",
       "      <td>8015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       adeo_product_id                                  mirakl_model_code  \\\n",
       "count          4565914                                            4565914   \n",
       "unique         3158410                                               3202   \n",
       "top           12105401  202265|PAPIER_PEINT|PAPIER_PEINT_FRISE_ET_FIBR...   \n",
       "freq                 9                                             148827   \n",
       "\n",
       "                                                    title     lang  \\\n",
       "count                                             4565914  4565914   \n",
       "unique                                            3885904        3   \n",
       "top     Vis à métaux Ultima à tête cylindrique hexagon...       FR   \n",
       "freq                                                  691  2810387   \n",
       "\n",
       "                                              description  \n",
       "count                                             4565914  \n",
       "unique                                            3040743  \n",
       "top     Papier peint intissé solide, résistant à l'eau...  \n",
       "freq                                                 8015  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cut.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_cut.copy()\n",
    "df_unique.drop(columns=[title_col, language_col, description_raw], inplace=True)\n",
    "df_unique = df_unique.drop_duplicates(subset=id_col, keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the no. of entries and models removed due to sample <= CUTOFF per model\n",
    "sample_cut_lackofsample = df.shape[0] - df_cut.shape[0]\n",
    "model_cut_lackofsample = df[label_raw_col].nunique() - df_cut[label_raw_col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if title or description exists - drop entries with no title and no description\n",
    "\n",
    "df_cut[\"product_info\"] = \"None\"\n",
    "df_cut[\"product_info\"].loc[\n",
    "    df_cut[title_col].notnull() & df_cut[description_raw].notnull()\n",
    "] = \"both\"\n",
    "df_cut[\"product_info\"].loc[\n",
    "    df_cut[title_col].notnull() & df_cut[description_raw].isnull()\n",
    "] = \"title_only\"\n",
    "df_cut[\"product_info\"].loc[\n",
    "    df_cut[title_col].isnull() & df_cut[description_raw].notnull()\n",
    "] = \"description_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = df_cut.loc[df_cut[\"product_info\"] != \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the no. of entries and models removed due to sample <= CUTOFF per model\n",
    "sample_cut_lackofinfo = df.shape[0] - df_cut.shape[0] - sample_cut_lackofsample\n",
    "model_cut_lackofinfo = (\n",
    "    df[label_raw_col].nunique() - df_cut[label_raw_col].nunique() - model_cut_lackofsample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the unique adeo_product_id\n",
    "# To ensure that a unique adeo_product_id exist in only 1 dataset - to avoid data leaking\n",
    "\n",
    "train_val, test = train_test_split(df_unique, test_size=0.1, stratify=df_unique[label_raw_col])\n",
    "train, val = train_test_split(train_val, test_size=0.1, stratify=train_val[label_raw_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge it back to the main df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val[label_raw_col]\n",
    "val = val.merge(df_cut, how=\"inner\", on=id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train[label_raw_col]\n",
    "train = train.merge(df_cut, how=\"inner\", on=id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test[label_raw_col]\n",
    "test = test.merge(df_cut, how=\"inner\", on=id_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def check_if_overlap(df1, df2, on_column):\n",
    "    # merge two dataFrames and add indicator column\n",
    "    all_df = pd.merge(df1, df2, on=on_column, how=\"left\", indicator=\"exists\")\n",
    "    # add column to show if each row in first DataFrame exists in second\n",
    "    all_df[\"exists\"] = np.where(all_df.exists == \"both\", True, False)\n",
    "    if all_df[\"exists\"].sum() == 0:\n",
    "        print(\"These 2 dataframes are not overlapped over \", on_column)\n",
    "    else:\n",
    "        print(\"There are overlapped entries!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These 2 dataframes are not overlapped over  adeo_product_id\n"
     ]
    }
   ],
   "source": [
    "check_if_overlap(val, train, id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These 2 dataframes are not overlapped over  adeo_product_id\n"
     ]
    }
   ],
   "source": [
    "check_if_overlap(test, train, id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These 2 dataframes are not overlapped over  adeo_product_id\n"
     ]
    }
   ],
   "source": [
    "check_if_overlap(test, val, id_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Full Dataset\n",
      "============================\n",
      "No. entries: 4566310\n",
      "No. of models (categories / label):  3372\n",
      "No. of entries removed due to num of samples < CUTOFF:  396\n",
      "No. of models removed due to num of samples < CUTOFF:  170\n",
      "No. of entries removed due to lack of product information (no title & no description):  0\n",
      "No. of models removed due to to lack of product information (no title & no description):  0\n",
      "No. of entries after cut  4565914\n",
      "No. of models after cut  3202\n",
      "============================\n",
      "Train Dataset\n",
      "============================\n",
      "No. entries: 3698108\n",
      "No. of models (categories / label):  3202\n",
      "============================\n",
      "Val Dataset\n",
      "============================\n",
      "No. entries: 410900\n",
      "No. of models (categories / label):  3104\n",
      "============================\n",
      "Test Dataset\n",
      "============================\n",
      "No. entries: 456906\n",
      "No. of models (categories / label):  3152\n",
      "============================\n",
      "Verify if Dataset is correct\n",
      "============================\n",
      "The total no. of entries matched!!\n"
     ]
    }
   ],
   "source": [
    "print(\"============================\")\n",
    "print(\"Full Dataset\")\n",
    "print(\"============================\")\n",
    "print(\"No. entries:\", df.shape[0])\n",
    "print(\"No. of models (categories / label): \", df[label_raw_col].nunique())\n",
    "\n",
    "print(\"No. of entries removed due to num of samples < CUTOFF: \", sample_cut_lackofsample)\n",
    "print(\"No. of models removed due to num of samples < CUTOFF: \", model_cut_lackofsample)\n",
    "\n",
    "print(\n",
    "    \"No. of entries removed due to lack of product information (no title & no description): \",\n",
    "    sample_cut_lackofinfo,\n",
    ")\n",
    "print(\n",
    "    \"No. of models removed due to to lack of product information (no title & no description): \",\n",
    "    model_cut_lackofinfo,\n",
    ")\n",
    "\n",
    "print(\"No. of entries after cut \", (df_cut.shape[0]))\n",
    "print(\"No. of models after cut \", (df_cut[label_raw_col].nunique()))\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Train Dataset\")\n",
    "print(\"============================\")\n",
    "print(\"No. entries:\", train.shape[0])\n",
    "print(\"No. of models (categories / label): \", train[label_raw_col].nunique())\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Val Dataset\")\n",
    "print(\"============================\")\n",
    "print(\"No. entries:\", val.shape[0])\n",
    "print(\"No. of models (categories / label): \", val[label_raw_col].nunique())\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Test Dataset\")\n",
    "print(\"============================\")\n",
    "print(\"No. entries:\", test.shape[0])\n",
    "print(\"No. of models (categories / label): \", test[label_raw_col].nunique())\n",
    "\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Verify if Dataset is correct\")\n",
    "print(\"============================\")\n",
    "if train.shape[0] + val.shape[0] + test.shape[0] == df_cut.shape[0]:\n",
    "    print(\"The total no. of entries matched!!\")\n",
    "else:\n",
    "    print(\"No. of entries matching ERROR!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://artefact-taxonomy-classification-datasets/3P_mirakl_multilang_v1/val.parquet'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{base_uri}/val.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val.to_parquet(f\"{base_uri}/val.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_parquet(f\"{base_uri}/test.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_parquet(f\"{base_uri}/train.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "10530e19dcdfe73a7151595320d247214b692837f071583cab392004ec8982fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
