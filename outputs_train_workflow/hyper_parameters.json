{
    "model_name": "distilbert-base-multilingual-cased",
    "experiment_description": "Multi-task small GRU model with multilanguage distilledBert tokenizer",
    "num_epoch": 20,
    "max_len": 512,
    "batch_size": 128,
    "freeze_backbone": true,
    "learning_rate": 0.0001,
    "projection_dim": 256,
    "dropout": 0.2,
    "data_balance": true,
    "upper_qn": 0.9,
    "lower_qn": 0.1,
    "lov_attribute_codes": [
        "02419",
        "01746",
        "00562",
        "15344",
        "99999"
    ],
    "train_set_uri": "../data/train_formatted.csv",
    "val_set_uri": "../data/val_formatted.csv",
    "test_set_uri": "../data/train_formatted.csv"
}